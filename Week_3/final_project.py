# -*- coding: utf-8 -*-
"""Final_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1axD_wMMAQvgohZj1t26QVARLNSFMlTwl
"""

import pandas as pd
import numpy as np
import os

import pandas as pd
import os

# Define file paths (update if needed)
file_paths = {
    "Economic_Indicators": "/content/Economic_Indicators.csv",
    "Environmental_Indicators": "/content/Environmental_Indicators.csv",
    "Public_Debt_Indicators": "/content/Public_Debt_Indicators.csv",
    "Social_Indicators": "/content/Social_Indicators.csv",
    "Statistical_Indicators": "/content/Statistical_Indicators.csv",
    "Countries": "/content/Countries.csv",
    "Series": "/content/Series.csv"
}

# Load all CSV files into a dictionary
dfs = {}
for name, path in file_paths.items():
    if os.path.exists(path):  # Check if file exists before loading
        dfs[name] = pd.read_csv(path)
        print(f"âœ… Loaded {name} ({dfs[name].shape[0]} rows, {dfs[name].shape[1]} columns)")
    else:
        print(f"âŒ {name} not found, skipping...")

# Standardize column names
expected_columns = {
    "Country Name": "country_name",
    "Country Code": "country_code",
    "Series Name": "series_name",
    "Series Code": "series_code"
}

for name, df in dfs.items():
    df.rename(columns=expected_columns, inplace=True)

# Handle wide to long transformation for yearly data
for name in ["Economic_Indicators", "Environmental_Indicators", "Social_Indicators", "Statistical_Indicators"]:
    if name in dfs:
        df = dfs[name]

        # Identify year columns (e.g., 2021, 2022, 2023)
        year_columns = [col for col in df.columns if col.isdigit()]

        # Convert wide to long format
        df = df.melt(id_vars=["country_name", "country_code", "series_name", "series_code"],
                     value_vars=year_columns,
                     var_name="year",
                     value_name="value")

        # Convert year to integer
        df["year"] = df["year"].astype(int)

        # Replace '..' with NaN
        df["value"].replace("..", None, inplace=True)

        # Convert value to numeric
        df["value"] = pd.to_numeric(df["value"], errors="coerce")

        # Save updated dataframe
        dfs[name] = df
        print(f"ðŸ“Œ Transformed {name} into long format.")

# Handle quarterly format for Public Debt Indicators
if "Public_Debt_Indicators" in dfs:
    df = dfs["Public_Debt_Indicators"]

    # Identify quarterly columns (e.g., 2021Q1, 2021Q2, ...)
    quarterly_columns = [col for col in df.columns if "Q" in col]

    # Convert wide to long format
    df = df.melt(id_vars=["country_name", "country_code", "series_name", "series_code"],
                 value_vars=quarterly_columns,
                 var_name="year_quarter",
                 value_name="value")

    # Extract year and quarter
    df["year"] = df["year_quarter"].str[:4].astype(int)  # Extract "2021" from "2021Q1"
    df["quarter"] = df["year_quarter"].str[4:]  # Extract "Q1" from "2021Q1"

    # Drop the original year_quarter column
    df.drop(columns=["year_quarter"], inplace=True)

    # Replace '..' with NaN
    df["value"].replace("..", None, inplace=True)

    # Convert value to numeric
    df["value"] = pd.to_numeric(df["value"], errors="coerce")

    # Save updated dataframe
    dfs["Public_Debt_Indicators"] = df
    print("ðŸ“Œ Transformed Public_Debt_Indicators into long format with separate year and quarter.")

# Display the transformed data
for name, df in dfs.items():
    print(f"\nðŸ” First 5 rows of {name}:")
    display(df.head())

# Save transformed data to CSV
for name, df in dfs.items():
    output_path = f"/content/{name}_transformed.csv"
    df.to_csv(output_path, index=False)
    print(f"ðŸ’¾ Saved {name}_transformed.csv")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

# Define file paths
file_paths = {
    "Economic_Indicators": "/content/Economic_Indicators_transformed.csv",
    "Environmental_Indicators": "/content/Environmental_Indicators_transformed.csv",
    "Public_Debt_Indicators": "/content/Public_Debt_Indicators_transformed.csv",
    "Social_Indicators": "/content/Social_Indicators_transformed.csv",
    "Statistical_Indicators": "/content/Statistical_Indicators_transformed.csv",
}

# Load all CSV files into a dictionary
dfs = {}
for name, path in file_paths.items():
    if os.path.exists(path):  # Check if file exists before loading
        dfs[name] = pd.read_csv(path)
        print(f"âœ… Loaded {name} ({dfs[name].shape[0]} rows, {dfs[name].shape[1]} columns)")
    else:
        print(f"âŒ {name} not found, skipping...")

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Display missing values summary
missing_summary = {name: df.isnull().sum().sum() for name, df in dfs.items()}
missing_summary_df = pd.DataFrame(list(missing_summary.items()), columns=["Dataset", "Total Missing Values"])

# Display missing summary as a table
print("ðŸ” Missing Values Summary:")
print(missing_summary_df)

# Generate missing values heatmaps
for name, df in dfs.items():
    plt.figure(figsize=(10, 6))
    sns.heatmap(df.isnull(), cbar=False, cmap="viridis", yticklabels=False)
    plt.title(f"Missing Values Heatmap - {name}")
    plt.show()

# Compute missing value percentage for each dataset
missing_percentages = {}
for name, df in dfs.items():
    total_values = df.size
    total_missing = df.isnull().sum().sum()
    percent_missing = (total_missing / total_values) * 100
    missing_percentages[name] = round(percent_missing, 2)

# Convert to DataFrame
missing_summary_df = pd.DataFrame(list(missing_percentages.items()), columns=["Dataset", "Missing Percentage"])
print("ðŸ” Missing Value Summary by Dataset:")
print(missing_summary_df)

# Handling missing values: Drop rows with missing values
dropped_rows = {}
for name, df in dfs.items():
    before_drop = df.shape[0]
    df.dropna(inplace=True)  # Drop rows with NaN values
    after_drop = df.shape[0]
    dropped_rows[name] = before_drop - after_drop
    print(f"ðŸ“‰ Dropped {dropped_rows[name]} rows from {name} due to missing values.")

# Save cleaned datasets back to CSV
for name, df in dfs.items():
    output_path = f"/content/{name}_cleaned.csv"
    df.to_csv(output_path, index=False)
    print(f"ðŸ’¾ Saved cleaned dataset: {name}_cleaned.csv")

print("\nðŸš€ âœ… Missing value handling complete! Cleaned datasets are saved.")

from sklearn.preprocessing import StandardScaler, MinMaxScaler

# Choose the type of scaling (uncomment one)
scaler = StandardScaler()  # Z-score normalization (mean = 0, std = 1)
# scaler = MinMaxScaler()  # Min-Max scaling (0 to 1)

for name, df in dfs.items():
    # Select only numerical columns
    numeric_cols = df.select_dtypes(include=['number']).columns

    if len(numeric_cols) > 0:
        df[numeric_cols] = scaler.fit_transform(df[numeric_cols])
        print(f"ðŸ“ Standardized numerical values in {name}.")

# Save the standardized data
for name, df in dfs.items():
    output_path = f"/content/{name}_standardized.csv"
    df.to_csv(output_path, index=False)
    print(f"ðŸ’¾ Saved standardized dataset: {name}_standardized.csv")

from sklearn.preprocessing import LabelEncoder

label_encoders = {}

for name, df in dfs.items():
    cat_cols = df.select_dtypes(include=['object']).columns  # Find categorical columns

    for col in cat_cols:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])  # Convert categorical to numeric
        label_encoders[col] = le  # Save encoder for future use
        print(f"ðŸ”  Encoded categorical column '{col}' in {name}.")

# Save encoded data
for name, df in dfs.items():
    output_path = f"/content/{name}_encoded.csv"
    df.to_csv(output_path, index=False)
    print(f"ðŸ’¾ Saved encoded dataset: {name}_encoded.csv")

for name, df in dfs.items():
    print(f"\nðŸ“Š Descriptive Statistics for {name}:")
    print(df.describe())

import matplotlib.pyplot as plt
import seaborn as sns

# Histograms for numerical distributions
for name, df in dfs.items():
    numeric_cols = df.select_dtypes(include=['number']).columns
    if len(numeric_cols) > 0:
        df[numeric_cols].hist(figsize=(12, 8), bins=20)
        plt.suptitle(f"Histogram - {name}")
        plt.show()

# Boxplots to check for outliers
for name, df in dfs.items():
    numeric_cols = df.select_dtypes(include=['number']).columns
    if len(numeric_cols) > 0:
        plt.figure(figsize=(12, 6))
        sns.boxplot(data=df[numeric_cols])
        plt.title(f"Boxplot - {name}")
        plt.xticks(rotation=90)
        plt.show()

# Correlation Heatmap
for name, df in dfs.items():
    numeric_cols = df.select_dtypes(include=['number'])
    if len(numeric_cols.columns) > 1:  # Only if there are multiple numeric cols
        plt.figure(figsize=(10, 6))
        sns.heatmap(numeric_cols.corr(), annot=True, cmap="coolwarm", fmt=".2f")
        plt.title(f"Correlation Heatmap - {name}")
        plt.show()

